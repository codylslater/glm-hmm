{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading env required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "# %%\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import ssm\n",
    "import autograd.numpy as np\n",
    "from LapseModel_ntex import lapse_model\n",
    "from lapse_utils_ntex import get_parmin, get_parmax, get_parstart, fit_lapse_multiple_init, \\\n",
    "    calculate_predictive_acc_lapse_model\n",
    "from glm_utils_ntex import fit_glm, calculate_predictive_acc_glm, \\\n",
    "    plot_input_vectors, append_zeros, fit_glm_multiple_init\n",
    "from glm_hmm_utils_ntex import calculate_predictive_acc_glmhmm_ntex_parted, \\\n",
    "    fit_glmhmm_multiple_init, get_posterior_states_labels, get_posterior_states_labels_parted\n",
    "from plotting_utils_ntex import plot_glmhmm_weights\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load mat file to a python dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = r\"/mnt/g/My Drive/#Projects/Project_Neurotransmitter-Exploration/GLM_HMM_Data/preprocessed_data/preprocessed_240_241_242_243_Datastore_created_26-Mar-2023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'preprocessed_input', 'preprocessed_label', 'preprocessed_session', 'preprocessed_trial_number', '__function_workspace__'])\n"
     ]
    }
   ],
   "source": [
    "loaded = scipy.io.loadmat(target)\n",
    "loaded_mat_keys = loaded.keys()\n",
    "print(loaded_mat_keys)\n",
    "input = loaded[\"preprocessed_input\"]\n",
    "label = loaded[\"preprocessed_label\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Due unknown reason, the labels are converted to a weird sahpe tensor wize size: x, 1, y, 1, 1, 1 (which should be x,y,1); Here I made it to correct shape, but not shure if such conversion is stable. Input is also disrrupted to size x,1,y,4 (which should be x,1,y,4), since this is not true tensor( or nd array) due to inconsistent numel in each element (different trial in each session), can not directly use numpy reshape\n",
    "2. the model only accept labels as type(int, np.int8, np.int16, np.int32, np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_compatible = [x[0] for x in input]\n",
    "label_compatible = [np.array([[y[0][0][0]] for y in x[0]]).astype(int) for x in label ]\n",
    "#print(label_compatible)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For HMM model,due to its nature of calculating posterior probability, the order of trial is very important. Thus the shuffling of data is in dimension of sessions. Here gives an example of 5-fold model training (iterations of using each 1/5 sessions of data as test set and the other 4/5 sessions as training set), the following part set up all necessary hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shuffled, y_shuffled = shuffle(input, label, random_state=66)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 5\n",
    "C = 2  # number of output types/categories here with only two: response or not\n",
    "D = 1  # dimension of data (observations)\n",
    "transition_alpha = 1  # Hyperparameter\n",
    "prior_sigma = 100  # Hyperparameter\n",
    "K_states = 3  # Number of states you wish to observe\n",
    "\n",
    "n_init = 5 # number of times for independent runs in which the one with the best predictive acc would be selected out\n",
    "N_em_iters = 500  # number of max iterations for the expectation-maximization algorithm, which is set to prevent non-converging situation\n",
    "global_fit = True  # If global_fit true, use GLM parameter as initial params for glmhmm\n",
    "# If global_fit false, pretrained glmhmm params are needed and used as as initial params for glmhmm\n",
    "\n",
    "\n",
    "# get time now and result storing path to saving data such as the trained glmhmm parameters\n",
    "results_dir = '../results/'\n",
    "N_property = len(input_shuffled[0][0])\n",
    "M_GLM = N_property-1  # Number of inputs for each trial for the model\n",
    "# Since GLM model already has the bias colum, so remove this column before feeding to it, which is column 4\n",
    "input_index_glm = list(range(0, M_GLM))\n",
    "M_HMM = N_property  # Number of inputs for each trial for the model\n",
    "input_index_hmm = list(range(0, M_HMM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(label_compatible[0][0][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following part is a for-loop training glm-hmm model on each (fold -1)/fold of data and tested by the other 1/fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae7b7a5f0a0441d8fbc3db73dba8f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2afa36c1f21d4144a8d1112378870cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38516663b3fd46d8917053f77173ae6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498834711a444ba196b858bcfa41e279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4cbd2b69a64fccbc2cab072dbd6db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552ac1cc858a4044b395b9f0b6a980a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4818693578b44ece8c2cd7f2aabfba07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b64a77ba7344993aa82e7f456db911b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0170ed72c4c74d6b9b41e1b494d98e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546d0b958d5c4746b1ca5693a4919189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686a3f58fd294adf99e80874f13450c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c955a01161ae4175884c5d1261c1bb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d535f1ad1194872afa9c99c8877be15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8dd21a9c4a4fe19cad10cf996ee216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863bbe50385a428ca44544ac2eb984d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc27e6739bd54d6fadd154a868cc8e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888794360aaf44bc9c87a4c4205b53df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d5081a65ad4b4db0a08ab3cfafef4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f741690a01d145569ebe913fc871dff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac445ad9c274c1fb473310180a9cb0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f076df70974ae281b6e3330c89679b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f277c581b11446a964b9623e7e35f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16bbdeedd4e4f30aa413087aff7c0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a0684340e94dc3bd40da7b220f13d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635f82b2d4cb44d3a925e5df6eead0aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8998060762766645, 0.8846694796061885, 0.90067214339059, 0.8993333333333333, 0.876750700280112]\n"
     ]
    }
   ],
   "source": [
    "input_shuffled, y_shuffled = shuffle(input_compatible, label_compatible,\n",
    "                                   random_state=66)\n",
    "data_size = len(input_shuffled)\n",
    "Acc_GLM_5fold = []\n",
    "Param_GLM_5fold = []\n",
    "Acc_HMM_5fold = []\n",
    "Param_HMM_5fold = []\n",
    "\n",
    "for j in range(fold):\n",
    "    # get hmm training and test set, for hmm training, the data should be parted into sessions\n",
    "    input_this_test_hmm = [\n",
    "        x[:, input_index_hmm]\n",
    "        for c, x in enumerate(input_shuffled)\n",
    "        if j*len(input_shuffled)/fold <= c <= (j+1)*len(input_shuffled)/fold]\n",
    "    y_this_test_hmm = [\n",
    "        x[:, :]\n",
    "        for c, x in enumerate(y_shuffled)\n",
    "        if j*len(input_shuffled)/fold <= c <= (j+1)*len(input_shuffled)/fold]\n",
    "    input_this_train_hmm = [\n",
    "        x[:, input_index_hmm]\n",
    "        for c, x in enumerate(input_shuffled)\n",
    "        if c < j*len(input_shuffled)/fold or c > (j+1)*len(input_shuffled)/fold]\n",
    "    y_this_train_hmm = [\n",
    "        x[:, :]\n",
    "        for c, x in enumerate(y_shuffled)\n",
    "        if c < j*len(input_shuffled)/fold or c > (j+1)*len(input_shuffled)/fold]\n",
    "\n",
    "    # get glm training and test set, for glm training, the data should not be parted, that concatenaed\n",
    "    input_this_test_glm = []\n",
    "    input_this_train_glm = []\n",
    "    y_this_test_glm = []\n",
    "    y_this_train_glm = []\n",
    "    for c, x in enumerate(input_shuffled):\n",
    "        if j*len(input_shuffled)/ fold <= c <= (j + 1)*len(input_shuffled)/ fold:\n",
    "            if len(input_this_test_glm) == 0:\n",
    "                input_this_test_glm = x[:, input_index_glm]\n",
    "                y_this_test_glm = y_shuffled[c]\n",
    "            else:\n",
    "                input_this_test_glm = np.concatenate((\n",
    "                    input_this_test_glm, x[:, input_index_glm]))\n",
    "                y_this_test_glm = np.concatenate((\n",
    "                    y_this_test_glm, y_shuffled[c]))\n",
    "        else:\n",
    "            if len(input_this_train_glm) == 0:\n",
    "                input_this_train_glm = x[:, input_index_glm]\n",
    "                y_this_train_glm = y_shuffled[c]\n",
    "            else:\n",
    "                input_this_train_glm = np.concatenate((\n",
    "                    input_this_train_glm, x[:, input_index_glm]))\n",
    "                y_this_train_glm = np.concatenate((\n",
    "                    y_this_train_glm, y_shuffled[c]))\n",
    "\n",
    "    # run GLM model training\n",
    "    best_param_glm, best_acc_glm = fit_glm_multiple_init(\n",
    "        input_this_train_glm, y_this_train_glm,\n",
    "        input_this_test_glm, y_this_test_glm,\n",
    "        M_GLM, C, n_init)\n",
    "    Param_GLM_5fold.append(best_param_glm)\n",
    "    Param_GLM_5fold.append(best_acc_glm)\n",
    "\n",
    "    # start GLM HMM training\n",
    "    now = datetime.now()\n",
    "    time_str = now.strftime(\"%Y-%m-%d-%H%M%S\")\n",
    "    weights_glmhmm_example, acc_glmhmm_example = fit_glmhmm_multiple_init(\n",
    "        input_this_train_hmm, y_this_train_hmm,\n",
    "        input_this_test_hmm, y_this_test_hmm,\n",
    "        [np.ones([len(x), 1]) for x in y_this_train_hmm],\n",
    "        # this parameter provides a function to exclude some trials, if you want to use all trials,\n",
    "        # create a matrix of ones in the same shape as the y dataset\n",
    "        K_states, D, M_HMM, C, N_em_iters, transition_alpha,\n",
    "        prior_sigma, global_fit, best_param_glm,\n",
    "        'training_cache/glmhmm_' + time_str,\n",
    "        n_init, partition=True)\n",
    "    Param_HMM_5fold.append(weights_glmhmm_example)\n",
    "    Acc_HMM_5fold.append(acc_glmhmm_example)\n",
    "print(Acc_HMM_5fold)\n",
    "                                  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save best trained model parameters and accuracy for each fold, they could later be used for plotting in python or used as pretrained glmhmm parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% save best trained model parameters and accuracy for each fold\n",
    "time_str = datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
    "results_dir = '../results/'\n",
    "with open(results_dir+'Accs_24x_NEmice_example_' + time_str, 'wb') as f:\n",
    "    # indent=2 is not needed but makes the file human-readable\n",
    "    # if the data is nested\n",
    "    pickle.dump(Acc_HMM_5fold, f)\n",
    "with open(results_dir+'Params_24x_NEmice_example_' + time_str, 'wb') as f:\n",
    "    # indent=2 is not needed but makes the file human-readable\n",
    "    # if the data is nested\n",
    "    pickle.dump(Param_HMM_5fold, f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best trained parameter and the example data before shuffling to calculate predicted labels and states of each trial in correct order, which could be saved (in npz format for python env and mat format for matlab env) and provide information for further nalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_param = Param_HMM_5fold[Acc_HMM_5fold.index(max(Acc_HMM_load))]\n",
    "K_states = 3\n",
    "#input_compatible\n",
    "#label_compatible\n",
    "# states_probs: for each trial what is its probability in state1, state2 and so on\n",
    "# predicted_states: basically find the max one among the states_probs for each trial\n",
    "# predicted_response_prob: the predicted probability of response\n",
    "# predicted_label: If predicted_response_prob > 50, labeled as response trial, otherwise no-response trial\n",
    "states_probs, predicted_states, predicted_label, predicted_response_prob = \\\n",
    "    get_posterior_states_labels_parted(\n",
    "        input_compatible, label_compatible,\n",
    "        Best_param, K_states, range(K_states))\n",
    "\n",
    "results_dir = '../results/'\n",
    "time_str =  datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
    "np.savez(results_dir+'predicted_states_and_labels_24x_NEmice_' + time_str + '.npz',\n",
    "         states_probs,\n",
    "         predicted_states,\n",
    "         predicted_response_prob,\n",
    "         predicted_label\n",
    "         )\n",
    "result_dir_2matlab = \"/mnt/g/My Drive/#Projects/Project_Neurotransmitter-Exploration/GLM_HMM_Data/GLM_HMM_processed_result/\"\n",
    "scipy.io.savemat(result_dir_2matlab+'predicted_states_and_labels_24x_NEmice_Python2mat' + time_str +'.mat',\n",
    "                 dict(\n",
    "                     states_probs = states_probs,\n",
    "                     predicted_states = predicted_states,\n",
    "                     predicted_response_prob = predicted_response_prob,\n",
    "                     predicted_label = predicted_label,\n",
    "                 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir_2matlab = \"/mnt/g/My Drive/#Projects/Project_Neurotransmitter-Exploration/GLM_HMM_Data/GLM_HMM_processed_result/\"\n",
    "scipy.io.savemat(result_dir_2matlab+'predicted_states_and_labels_24x_NEmice_Python2mat' + time_str +'.mat',\n",
    "                 dict(\n",
    "                     states_probs = states_probs,\n",
    "                     predicted_states = predicted_states,\n",
    "                     predicted_response_prob = predicted_response_prob,\n",
    "                     predicted_label = predicted_label,\n",
    "                 ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glmhmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
